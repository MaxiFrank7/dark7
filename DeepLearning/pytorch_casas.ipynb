{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30a5891d",
   "metadata": {},
   "source": [
    "1. El Problema: Predicción de Precios de Casas\n",
    "Vamos a simular un problema clásico de regresión. Tenemos un DataFrame con 3 columnas (Características o Features):\n",
    "\n",
    "* Metros Cuadrados (ej: 50 a 200).\n",
    "\n",
    "* Antigüedad (ej: 1 a 50 años).\n",
    "\n",
    "* Distancia al centro (ej: 0.5 a 20 km).\n",
    "\n",
    "Y queremos predecir el Precio (Target).\n",
    "\n",
    "2. El Puente: De Pandas a PyTorch\n",
    "Aquí hay una regla de oro que un Senior Engineer nunca olvida:\n",
    "\n",
    "⚠️ Regla de Oro: A las redes neuronales NO les gustan los números grandes ni los rangos dispares.\n",
    "\n",
    "Si metes \"100 metros\" y \"0.5 km\" juntos, la red se confundirá porque 100 es mucho más grande que 0.5, aunque la distancia sea importante. Solución: Debemos normalizar los datos (hacer que todo esté más o menos entre -1 y 1) antes de convertirlos a Tensores.\n",
    "\n",
    "Usaremos StandardScaler de Scikit-Learn para esto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84ed1fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos listos.\n",
      "Ejemplo X normalizado: [ 0.16292116 -0.20180036  0.22807746]\n",
      "Ejemplo y normalizado: [0.16163998]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Simulación de un CSV cargado en Pandas\n",
    "data = {\n",
    "    'metros': np.random.randint(50, 200, 1000),\n",
    "    'antiguedad': np.random.randint(1, 50, 1000),\n",
    "    'distancia': np.random.uniform(0.5, 20, 1000),\n",
    "    'precio': np.zeros(1000) # Placeholder\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Generamos un precio lógico: Precio base + (Metros * 1000) - (Antigüedad * 500) ...\n",
    "df['precio'] = 50000 + (df['metros'] * 1000) - (df['antiguedad'] * 500) - (df['distancia'] * 1000)\n",
    "\n",
    "# 2. Separamos Features (X) y Target (y)\n",
    "X_numpy = df[['metros', 'antiguedad', 'distancia']].values\n",
    "y_numpy = df['precio'].values.reshape(-1, 1) # Importante: reshape a columna\n",
    "\n",
    "# 3. NORMALIZACIÓN (CRÍTICO PARA REDES NEURONALES)\n",
    "scaler_x = StandardScaler()\n",
    "scaler_y = StandardScaler() # Escalamos también el precio para que la Loss no sea gigante\n",
    "\n",
    "X_scaled = scaler_x.fit_transform(X_numpy)\n",
    "y_scaled = scaler_y.fit_transform(y_numpy)\n",
    "\n",
    "print(f\"Datos listos.\")\n",
    "print(f\"Ejemplo X normalizado: {X_scaled[0]}\")\n",
    "print(f\"Ejemplo y normalizado: {y_scaled[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff9e483",
   "metadata": {},
   "source": [
    "Tu Misión:\n",
    "\n",
    "1) Crea la clase HouseDataset:\n",
    "\n",
    "* En el __init__, debe recibir dos argumentos: features y targets.\n",
    "\n",
    "* Dentro del __init__, convierte esos arrays de numpy a Tensores de PyTorch tipo float32.\n",
    "\n",
    "* Pista: torch.tensor(..., dtype=torch.float32)\n",
    "\n",
    "Implementa __len__ y __getitem__.\n",
    "\n",
    "2) Crea la clase HouseModel:\n",
    "\n",
    "* Entrada: 3 neuronas (porque tenemos 3 features).\n",
    "\n",
    "* Oculta: 2 capas ocultas de 64 neuronas cada una con ReLU.\n",
    "\n",
    "* Salida: 1 neurona (el precio). ¡OJO! No uses activación en la salida final (queremos un valor lineal continuo, no una probabilidad).\n",
    "\n",
    "Escribe el código de estas dos clases y instáncialas.\n",
    "\n",
    "Instancia el dataset pasando X_scaled y y_scaled.\n",
    "\n",
    "Instancia el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aea9e45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HouseDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features=torch.tensor(data=features, dtype=torch.float32)\n",
    "        self.targets=torch.tensor(data=targets, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # DEVOLVEMOS TUPLA: (Datos, Precio)\n",
    "        return self.features[index], self.targets[index]\n",
    "\n",
    "class HouseModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #primera de 3 a 64 ocultas. Entrada -> Oculta\n",
    "        self.capa1=nn.Linear(in_features=3,out_features=64)\n",
    "        self.activacion=nn.ReLU()\n",
    "        #oculta -> oculta. segunda transformación (Profundidad): De 64 a 64\n",
    "        self.capa2=nn.Linear(in_features=64,out_features=64)\n",
    "        #capa Final (Compresión): De 64 a 1 solo precio\n",
    "        self.salida=nn.Linear(in_features=64,out_features=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Debe pasar x a través de: capa1 -> activacion -> capa2 -> activacion -> salida.\"\"\"\n",
    "        x=self.capa1(x)\n",
    "        x=self.activacion(x)\n",
    "        x=self.capa2(x)\n",
    "        x=self.activacion(x)\n",
    "        x=self.salida(x)\n",
    "        return x\n",
    "\n",
    "modelo=HouseModel()\n",
    "dataset=HouseDataset(features=X_scaled, targets=y_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e0b303",
   "metadata": {},
   "source": [
    "Vas a escribir el script de entrenamiento completo tú solo, uniendo todo lo que hemos visto.\n",
    "\n",
    "Requisitos Técnicos:\n",
    "\n",
    "* DataLoader: Instáncialo con tu dataset, batch_size=32 y shuffle=True.\n",
    "\n",
    "* Loss Function: Como es un problema de regresión (predecir valores continuos), DEBES usar nn.MSELoss() (Error Cuadrático Medio).\n",
    "\n",
    "* Optimizador: Usa torch.optim.Adam con un learning rate (lr) de 0.001. Adam suele funcionar mejor que SGD para estos datos.\n",
    "\n",
    "* Bucle: Entrena por 20 épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3e70355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1 | Loss Promedio: 0.00039\n",
      "Época 2 | Loss Promedio: 0.00020\n",
      "Época 3 | Loss Promedio: 0.00014\n",
      "Época 4 | Loss Promedio: 0.00014\n",
      "Época 5 | Loss Promedio: 0.00012\n",
      "Época 6 | Loss Promedio: 0.00014\n",
      "Época 7 | Loss Promedio: 0.00013\n",
      "Época 8 | Loss Promedio: 0.00017\n",
      "Época 9 | Loss Promedio: 0.00013\n",
      "Época 10 | Loss Promedio: 0.00009\n",
      "Época 11 | Loss Promedio: 0.00007\n",
      "Época 12 | Loss Promedio: 0.00011\n",
      "Época 13 | Loss Promedio: 0.00017\n",
      "Época 14 | Loss Promedio: 0.00008\n",
      "Época 15 | Loss Promedio: 0.00011\n",
      "Época 16 | Loss Promedio: 0.00014\n",
      "Época 17 | Loss Promedio: 0.00007\n",
      "Época 18 | Loss Promedio: 0.00010\n",
      "Época 19 | Loss Promedio: 0.00005\n",
      "Época 20 | Loss Promedio: 0.00005\n"
     ]
    }
   ],
   "source": [
    "#Crear el DataLoader\n",
    "#batch_size=32: Entregará paquetes de 32 datos\n",
    "#shuffle=True: Barajará los datos en cada época\n",
    "loader = DataLoader(dataset=dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "#loss function\n",
    "loss_function=nn.MSELoss()\n",
    "#optimizador\n",
    "optimizador=torch.optim.Adam(params=modelo.parameters(),lr=0.001)\n",
    "#bucle\n",
    "epochs=20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss_acum = 0\n",
    "    \n",
    "    for batch_x, batch_y in loader:      \n",
    "        # 1. Forward\n",
    "        prediccion = modelo(batch_x)\n",
    "        \n",
    "        # 2. Calcular Loss\n",
    "        loss = loss_function(prediccion, batch_y)\n",
    "        \n",
    "        # 3. Limpiar gradientes previos\n",
    "        optimizador.zero_grad()\n",
    "        \n",
    "        # 4. Backward (Calcular gradientes)\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. Actualizar pesos\n",
    "        optimizador.step()\n",
    "        \n",
    "        # Acumulamos el error para monitorear (opcional)\n",
    "        loss_acum += loss.item()\n",
    "    \n",
    "    # Reporte por epoch\n",
    "    promedio_loss = loss_acum / len(loader)\n",
    "    print(f\"Época {epoch+1} | Loss Promedio: {promedio_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f52ad2",
   "metadata": {},
   "source": [
    "Llega un cliente a tu inmobiliaria.\n",
    "\n",
    "La Casa:Metros: 120 $m^2$\n",
    "\n",
    "Antigüedad: 10 años\n",
    "\n",
    "Distancia: 5.0 km\n",
    "\n",
    "Tu Misión:Usa tu modelo entrenado para predecir el precio de esta casa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a107f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El precio estimado es: $160,196.98\n"
     ]
    }
   ],
   "source": [
    "# 1. Definimos los datos de la casa nueva (en el mismo orden que entrenamos)\n",
    "# [metros, antiguedad, distancia]\n",
    "casa_nueva = np.array([[120, 10, 5.0]]) \n",
    "\n",
    "# 2. Normalizamos la entrada (Usamos el MISMO scaler_x del entrenamiento)\n",
    "casa_nueva_scaled = scaler_x.transform(casa_nueva)\n",
    "\n",
    "# 3. Convertimos a Tensor (recuerda el tipo de dato y el dispositivo)\n",
    "# RELLENA AQUI: casa_tensor = ...\n",
    "casa_tensor = torch.tensor(casa_nueva_scaled, dtype=torch.float32)\n",
    "\n",
    "# 4. Predicción\n",
    "modelo.eval() # Modo evaluación\n",
    "with torch.no_grad(): # Apagamos gradientes\n",
    "    # RELLENA AQUI: Haz el pase forward\n",
    "    prediccion_scaled = modelo(casa_tensor)\n",
    "\n",
    "# 5. Des-normalizamos el precio (De vuelta a dólares)\n",
    "# Usamos scaler_y.inverse_transform\n",
    "# OJO: inverse_transform espera un array de numpy, no un tensor.\n",
    "precio_final = scaler_y.inverse_transform(prediccion_scaled.numpy())\n",
    "\n",
    "print(f\"El precio estimado es: ${precio_final[0][0]:,.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30a5891d",
   "metadata": {},
   "source": [
    "1. El Problema: Predicci√≥n de Precios de Casas\n",
    "Vamos a simular un problema cl√°sico de regresi√≥n. Tenemos un DataFrame con 3 columnas (Caracter√≠sticas o Features):\n",
    "\n",
    "* Metros Cuadrados (ej: 50 a 200).\n",
    "\n",
    "* Antig√ºedad (ej: 1 a 50 a√±os).\n",
    "\n",
    "* Distancia al centro (ej: 0.5 a 20 km).\n",
    "\n",
    "Y queremos predecir el Precio (Target).\n",
    "\n",
    "2. El Puente: De Pandas a PyTorch\n",
    "Aqu√≠ hay una regla de oro que un Senior Engineer nunca olvida:\n",
    "\n",
    "‚ö†Ô∏è Regla de Oro: A las redes neuronales NO les gustan los n√∫meros grandes ni los rangos dispares.\n",
    "\n",
    "Si metes \"100 metros\" y \"0.5 km\" juntos, la red se confundir√° porque 100 es mucho m√°s grande que 0.5, aunque la distancia sea importante. Soluci√≥n: Debemos normalizar los datos (hacer que todo est√© m√°s o menos entre -1 y 1) antes de convertirlos a Tensores.\n",
    "\n",
    "Usaremos StandardScaler de Scikit-Learn para esto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84ed1fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos listos.\n",
      "Ejemplo X normalizado: [ 1.64854767 -0.33145076  1.49200015]\n",
      "Ejemplo y normalizado: [1.4850106]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Simulaci√≥n de un CSV cargado en Pandas\n",
    "data = {\n",
    "    'metros': np.random.randint(50, 200, 1000),\n",
    "    'antiguedad': np.random.randint(1, 50, 1000),\n",
    "    'distancia': np.random.uniform(0.5, 20, 1000),\n",
    "    'precio': np.zeros(1000) # Placeholder\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Generamos un precio l√≥gico: Precio base + (Metros * 1000) - (Antig√ºedad * 500) ...\n",
    "df['precio'] = 50000 + (df['metros'] * 1000) - (df['antiguedad'] * 500) - (df['distancia'] * 1000)\n",
    "\n",
    "# 2. Separamos Features (X) y Target (y)\n",
    "X_numpy = df[['metros', 'antiguedad', 'distancia']].values\n",
    "y_numpy = df['precio'].values.reshape(-1, 1) # Importante: reshape a columna\n",
    "\n",
    "# 3. NORMALIZACI√ìN (CR√çTICO PARA REDES NEURONALES)\n",
    "scaler_x = StandardScaler()\n",
    "scaler_y = StandardScaler() # Escalamos tambi√©n el precio para que la Loss no sea gigante\n",
    "\n",
    "X_scaled = scaler_x.fit_transform(X_numpy)\n",
    "y_scaled = scaler_y.fit_transform(y_numpy)\n",
    "\n",
    "print(f\"Datos listos.\")\n",
    "print(f\"Ejemplo X normalizado: {X_scaled[0]}\")\n",
    "print(f\"Ejemplo y normalizado: {y_scaled[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff9e483",
   "metadata": {},
   "source": [
    "Tu Misi√≥n:\n",
    "\n",
    "1) Crea la clase HouseDataset:\n",
    "\n",
    "* En el __init__, debe recibir dos argumentos: features y targets.\n",
    "\n",
    "* Dentro del __init__, convierte esos arrays de numpy a Tensores de PyTorch tipo float32.\n",
    "\n",
    "* Pista: torch.tensor(..., dtype=torch.float32)\n",
    "\n",
    "Implementa __len__ y __getitem__.\n",
    "\n",
    "2) Crea la clase HouseModel:\n",
    "\n",
    "* Entrada: 3 neuronas (porque tenemos 3 features).\n",
    "\n",
    "* Oculta: 2 capas ocultas de 64 neuronas cada una con ReLU.\n",
    "\n",
    "* Salida: 1 neurona (el precio). ¬°OJO! No uses activaci√≥n en la salida final (queremos un valor lineal continuo, no una probabilidad).\n",
    "\n",
    "Escribe el c√≥digo de estas dos clases y inst√°ncialas.\n",
    "\n",
    "Instancia el dataset pasando X_scaled y y_scaled.\n",
    "\n",
    "Instancia el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aea9e45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HouseDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features=torch.tensor(data=features, dtype=torch.float32)\n",
    "        self.targets=torch.tensor(data=targets, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # DEVOLVEMOS TUPLA: (Datos, Precio)\n",
    "        return self.features[index], self.targets[index]\n",
    "\n",
    "class HouseModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #primera de 3 a 64 ocultas. Entrada -> Oculta\n",
    "        self.capa1=nn.Linear(in_features=3,out_features=64)\n",
    "        self.activacion=nn.ReLU()\n",
    "        #oculta -> oculta. segunda transformaci√≥n (Profundidad): De 64 a 64\n",
    "        self.capa2=nn.Linear(in_features=64,out_features=64)\n",
    "        #capa Final (Compresi√≥n): De 64 a 1 solo precio\n",
    "        self.salida=nn.Linear(in_features=64,out_features=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Debe pasar x a trav√©s de: capa1 -> activacion -> capa2 -> activacion -> salida.\"\"\"\n",
    "        x=self.capa1(x)\n",
    "        x=self.activacion(x)\n",
    "        x=self.capa2(x)\n",
    "        x=self.activacion(x)\n",
    "        x=self.salida(x)\n",
    "        return x\n",
    "\n",
    "modelo=HouseModel()\n",
    "dataset=HouseDataset(features=X_scaled, targets=y_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e0b303",
   "metadata": {},
   "source": [
    "Vas a escribir el script de entrenamiento completo t√∫ solo, uniendo todo lo que hemos visto.\n",
    "\n",
    "Requisitos T√©cnicos:\n",
    "\n",
    "* DataLoader: Inst√°ncialo con tu dataset, batch_size=32 y shuffle=True.\n",
    "\n",
    "* Loss Function: Como es un problema de regresi√≥n (predecir valores continuos), DEBES usar nn.MSELoss() (Error Cuadr√°tico Medio).\n",
    "\n",
    "* Optimizador: Usa torch.optim.Adam con un learning rate (lr) de 0.001. Adam suele funcionar mejor que SGD para estos datos.\n",
    "\n",
    "* Bucle: Entrena por 20 √©pocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3e70355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√âpoca 1 | Loss Promedio: 0.42114\n",
      "√âpoca 2 | Loss Promedio: 0.01153\n",
      "√âpoca 3 | Loss Promedio: 0.00381\n",
      "√âpoca 4 | Loss Promedio: 0.00235\n",
      "√âpoca 5 | Loss Promedio: 0.00204\n",
      "√âpoca 6 | Loss Promedio: 0.00156\n",
      "√âpoca 7 | Loss Promedio: 0.00121\n",
      "√âpoca 8 | Loss Promedio: 0.00100\n",
      "√âpoca 9 | Loss Promedio: 0.00079\n",
      "√âpoca 10 | Loss Promedio: 0.00065\n",
      "√âpoca 11 | Loss Promedio: 0.00052\n",
      "√âpoca 12 | Loss Promedio: 0.00042\n",
      "√âpoca 13 | Loss Promedio: 0.00036\n",
      "√âpoca 14 | Loss Promedio: 0.00032\n",
      "√âpoca 15 | Loss Promedio: 0.00026\n",
      "√âpoca 16 | Loss Promedio: 0.00022\n",
      "√âpoca 17 | Loss Promedio: 0.00020\n",
      "√âpoca 18 | Loss Promedio: 0.00017\n",
      "√âpoca 19 | Loss Promedio: 0.00015\n",
      "√âpoca 20 | Loss Promedio: 0.00015\n"
     ]
    }
   ],
   "source": [
    "#Crear el DataLoader\n",
    "#batch_size=32: Entregar√° paquetes de 32 datos\n",
    "#shuffle=True: Barajar√° los datos en cada √©poca\n",
    "loader = DataLoader(dataset=dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "#loss function\n",
    "loss_function=nn.MSELoss()\n",
    "#optimizador\n",
    "optimizador=torch.optim.Adam(params=modelo.parameters(),lr=0.001)\n",
    "#bucle\n",
    "epochs=20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss_acum = 0\n",
    "    \n",
    "    for batch_x, batch_y in loader:      \n",
    "        # 1. Forward\n",
    "        prediccion = modelo(batch_x)\n",
    "        \n",
    "        # 2. Calcular Loss\n",
    "        loss = loss_function(prediccion, batch_y)\n",
    "        \n",
    "        # 3. Limpiar gradientes previos\n",
    "        optimizador.zero_grad()\n",
    "        \n",
    "        # 4. Backward (Calcular gradientes)\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. Actualizar pesos\n",
    "        optimizador.step()\n",
    "        \n",
    "        # Acumulamos el error para monitorear (opcional)\n",
    "        loss_acum += loss.item()\n",
    "    \n",
    "    # Reporte por epoch\n",
    "    promedio_loss = loss_acum / len(loader)\n",
    "    print(f\"√âpoca {epoch+1} | Loss Promedio: {promedio_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f52ad2",
   "metadata": {},
   "source": [
    "Llega un cliente a tu inmobiliaria.\n",
    "\n",
    "La Casa:Metros: 120 $m^2$\n",
    "\n",
    "Antig√ºedad: 10 a√±os\n",
    "\n",
    "Distancia: 5.0 km\n",
    "\n",
    "Tu Misi√≥n:Usa tu modelo entrenado para predecir el precio de esta casa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a107f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El precio estimado es: $159,905.00\n"
     ]
    }
   ],
   "source": [
    "# 1. Definimos los datos de la casa nueva (en el mismo orden que entrenamos)\n",
    "# [metros, antiguedad, distancia]\n",
    "casa_nueva = np.array([[120, 10, 5.0]]) \n",
    "\n",
    "# 2. Normalizamos la entrada (Usamos el MISMO scaler_x del entrenamiento)\n",
    "casa_nueva_scaled = scaler_x.transform(casa_nueva)\n",
    "\n",
    "# 3. Convertimos a Tensor (recuerda el tipo de dato y el dispositivo)\n",
    "# RELLENA AQUI: casa_tensor = ...\n",
    "casa_tensor = torch.tensor(casa_nueva_scaled, dtype=torch.float32)\n",
    "\n",
    "# 4. Predicci√≥n\n",
    "modelo.eval() # Modo evaluaci√≥n\n",
    "with torch.no_grad(): # Apagamos gradientes\n",
    "    # RELLENA AQUI: Haz el pase forward\n",
    "    prediccion_scaled = modelo(casa_tensor)\n",
    "\n",
    "# 5. Des-normalizamos el precio (De vuelta a d√≥lares)\n",
    "# Usamos scaler_y.inverse_transform\n",
    "# OJO: inverse_transform espera un array de numpy, no un tensor.\n",
    "precio_final = scaler_y.inverse_transform(prediccion_scaled.numpy())\n",
    "\n",
    "print(f\"El precio estimado es: ${precio_final[0][0]:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9075a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de casas VIP: 501 de 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dark7 120gb\\AppData\\Local\\Temp\\ipykernel_21164\\4103088138.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.features=torch.tensor(data=features, dtype=torch.float32)\n",
      "C:\\Users\\Dark7 120gb\\AppData\\Local\\Temp\\ipykernel_21164\\4103088138.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.targets=torch.tensor(data=targets, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# 1. Creamos la etiqueta binaria basada en el precio real\n",
    "# Si precio > 150000 -> 1 (VIP), si no -> 0 (Normal)\n",
    "umbral = 150000\n",
    "y_binario = (df['precio'].values > umbral).astype(int).reshape(-1, 1)\n",
    "\n",
    "# 2. Convertimos a Tensor Float32\n",
    "# ¬°OJO! BCELoss espera que las etiquetas sean Float, no Long/Int.\n",
    "y_train_class = torch.tensor(y_binario, dtype=torch.float32)\n",
    "\n",
    "# 3. Reusamos tus Features normalizados (X_scaled) que ya ten√≠as\n",
    "X_train_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "\n",
    "# 4. Creamos el nuevo Dataset y Loader\n",
    "dataset_class = HouseDataset(X_train_tensor, y_train_class)\n",
    "loader_class = DataLoader(dataset_class, batch_size=32, shuffle=True)\n",
    "\n",
    "print(f\"Total de casas VIP: {y_binario.sum()} de {len(y_binario)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069e6f8a",
   "metadata": {},
   "source": [
    "Tu Misi√≥n:\n",
    "\n",
    "Escribe el script de entrenamiento para Clasificaci√≥n.\n",
    "\n",
    "* Instancia el modelo: modelo = HouseModel() (Reinst√°ncialo para borrar los pesos viejos).\n",
    "\n",
    "* Define la Loss: Usa nn.BCEWithLogitsLoss().\n",
    "\n",
    "* Define el Optimizador: Adam, lr=0.001.Bucle: Entrena por 20 √©pocas.\n",
    "\n",
    "üí° Reto Extra (Opcional pero recomendado):En el print final de cada √©poca, adem√°s de la Loss, intenta calcular la Accuracy (Precisi√≥n).\n",
    "\n",
    "Pista: La predicci√≥n cruda (logits) pasa por una sigmoide. Si el resultado $> 0.5$, es un 1. Compara eso con batch_y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92acd718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√âpoch 1 | Loss Promedio: 0.59347 | Accuracy: 75.30%\n",
      "√âpoch 2 | Loss Promedio: 0.34230 | Accuracy: 94.00%\n",
      "√âpoch 3 | Loss Promedio: 0.17185 | Accuracy: 97.90%\n",
      "√âpoch 4 | Loss Promedio: 0.10501 | Accuracy: 98.70%\n",
      "√âpoch 5 | Loss Promedio: 0.07580 | Accuracy: 99.10%\n",
      "√âpoch 6 | Loss Promedio: 0.05920 | Accuracy: 99.60%\n",
      "√âpoch 7 | Loss Promedio: 0.05098 | Accuracy: 99.60%\n",
      "√âpoch 8 | Loss Promedio: 0.04164 | Accuracy: 99.50%\n",
      "√âpoch 9 | Loss Promedio: 0.03654 | Accuracy: 99.60%\n",
      "√âpoch 10 | Loss Promedio: 0.03300 | Accuracy: 99.70%\n",
      "√âpoch 11 | Loss Promedio: 0.02990 | Accuracy: 99.80%\n",
      "√âpoch 12 | Loss Promedio: 0.02707 | Accuracy: 99.80%\n",
      "√âpoch 13 | Loss Promedio: 0.02477 | Accuracy: 99.80%\n",
      "√âpoch 14 | Loss Promedio: 0.02190 | Accuracy: 99.90%\n",
      "√âpoch 15 | Loss Promedio: 0.02073 | Accuracy: 99.90%\n",
      "√âpoch 16 | Loss Promedio: 0.02053 | Accuracy: 99.80%\n",
      "√âpoch 17 | Loss Promedio: 0.01785 | Accuracy: 99.90%\n",
      "√âpoch 18 | Loss Promedio: 0.01588 | Accuracy: 99.90%\n",
      "√âpoch 19 | Loss Promedio: 0.01584 | Accuracy: 100.00%\n",
      "√âpoch 20 | Loss Promedio: 0.01541 | Accuracy: 99.90%\n"
     ]
    }
   ],
   "source": [
    "modelo=HouseModel()\n",
    "loss_function=nn.BCEWithLogitsLoss()\n",
    "optimizador=torch.optim.Adam(params=modelo.parameters(),lr=0.001)\n",
    "epochs=20\n",
    "for epoch in range(epochs):\n",
    "    loss_acumulada=0\n",
    "    correctos_acumulados = 0\n",
    "    total_muestras = 0\n",
    "\n",
    "    for batch_x, batch_y in loader_class:      \n",
    "        # 1. Forward\n",
    "        prediccion = modelo(batch_x)\n",
    "        # 2. Calcular Loss\n",
    "        loss = loss_function(prediccion, batch_y)\n",
    "        # 3. Limpiar gradientes previos\n",
    "        optimizador.zero_grad()\n",
    "        # 4. Backward (Calcular gradientes)\n",
    "        loss.backward()\n",
    "        # 5. Actualizar pesos\n",
    "        optimizador.step()\n",
    "        # Acumulamos el error para monitorear (opcional)\n",
    "        loss_acumulada += loss.item()\n",
    "\n",
    "        #calculo accuracy\n",
    "        #convertir logits a probabilidades\n",
    "        probs = torch.sigmoid(prediccion)\n",
    "        #Convertir a 0 o 1 (Decisi√≥n)\n",
    "        preds = (probs > 0.5).float()\n",
    "        #Contar aciertos (True si son iguales, False si no)\n",
    "        correctos_acumulados += (preds == batch_y).sum().item()\n",
    "        total_muestras += batch_y.size(0) # Sumamos 32 (tama√±o del batch)\n",
    "    # Reporte por epoch\n",
    "    promedio_loss = loss_acumulada / len(loader_class)\n",
    "    accuracy_epoch = correctos_acumulados / total_muestras\n",
    "    print(f\"√âpoch {epoch+1} | Loss Promedio: {promedio_loss:.5f} | Accuracy: {accuracy_epoch*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddff2107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As√≠ se ven tus par√°metros entrenados:\n",
      "odict_keys(['capa1.weight', 'capa1.bias', 'capa2.weight', 'capa2.bias', 'salida.weight', 'salida.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(\"As√≠ se ven tus par√°metros entrenados:\")\n",
    "print(modelo.state_dict().keys())\n",
    "# Ver√°s algo como: 'capa1.weight', 'capa1.bias', etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "899bdf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬°Modelo guardado en el disco!\n"
     ]
    }
   ],
   "source": [
    "torch.save(modelo.state_dict(), \"modelo_casas_vip.pth\")\n",
    "print(\"¬°Modelo guardado en el disco!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48eb9463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad de ser VIP: 0.9958\n"
     ]
    }
   ],
   "source": [
    "# --- TU C√ìDIGO CORREGIDO ---\n",
    "torch.save(modelo.state_dict(), \"mi_mejor_modelo.pth\")\n",
    "\n",
    "nuevo_modelo = HouseModel()\n",
    "checkpoint = torch.load(\"mi_mejor_modelo.pth\") \n",
    "nuevo_modelo.load_state_dict(checkpoint)\n",
    "\n",
    "# Correcci√≥n aqu√≠: usamos la variable que acabas de crear\n",
    "nuevo_modelo.eval() \n",
    "\n",
    "# --- LO QUE NO ENTEND√çAS (LA PRUEBA DE FUEGO) ---\n",
    "# Usamos el tensor de la casa de prueba (120m2, 10 a√±os...)\n",
    "# Asumimos que 'casa_tensor' todav√≠a existe en tu memoria del ejercicio anterior.\n",
    "# Si no, recuerda: era la casa de 160.000 USD (que ES VIP).\n",
    "\n",
    "with torch.no_grad():\n",
    "    # 1. Pasamos la casa por el modelo NUEVO\n",
    "    logits = nuevo_modelo(casa_tensor)\n",
    "    \n",
    "    # 2. Convertimos a probabilidad (0 a 1)\n",
    "    probabilidad = torch.sigmoid(logits)\n",
    "\n",
    "print(f\"Probabilidad de ser VIP: {probabilidad.item():.4f}\")\n",
    "# Si el modelo aprendi√≥ bien, esto deber√≠a ser muy cercano a 1.0 (ej: 0.99)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
